Category,Feature,URL,Description,Status (Azure),Risk Assessment (Human),Risk Assessment (AI),Source,Last Checked
AI and machine learning,Agent Framework: On-Behalf-Of-User Authorization,https://docs.databricks.com/aws/en/generative-ai/agent-framework/author-agent#on-behalf-of-user-authentication,"This feature enables on-behalf-of-user authentication for generative AI agents deployed via Mosaic AI Agent Framework. When you deploy an agent that performs on-behalf of end user access using Mosaic AI agent framework, the agent will be able to access Databricks resources using the identity of the agent invoker.",PUBLIC_PREVIEW,-,High — agent acts with invoker's identity and permissions,Workspace,2026-02-05
AI and machine learning,ai_classify(),https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/functions/ai_classify,"The ai_classify() function enables you to classify input text directly in SQL using state-of-the-art generative AI models provided by Databricks Foundation Model APIs. By supplying a set of labels, you can declaratively assign categories to unstructured text and iterate on this agent using Databricks Agent Bricks.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
AI and machine learning,ai_extract(),https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/functions/ai_extract,"The ai_extract() function enables you to extract structured entities from unstructured text directly in SQL using state-of-the-art generative AI models provided by Databricks Foundation Model APIs. After specifying a target schema, you can declaratively transform raw text into structured outputs and iterate on this schema and agent using Databricks Agent Bricks.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
AI and machine learning,AI functions overview,https://learn.microsoft.com/en-gb/azure/databricks/large-language-models/ai-functions,"This article describes Azure Databricks AI Functions and the supported functions. What are AI Functions? AI Functions are built-in functions that you can use to apply AI, like text translation or sentiment analysis, on your data that is stored on Dat...",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
AI and machine learning,AI Gateway,https://learn.microsoft.com/en-gb/azure/databricks/ai-gateway/,"This article describes Mosaic AI Gateway, the Databricks solution for governing and monitoring access to supported generative AI models and their associated model serving endpoints.",GA,-,-,Docs,2026-02-08
AI and machine learning,AI Guardrails,https://learn.microsoft.com/en-gb/azure/databricks/ai-gateway/,"AI Guardrails for Mosaic AI Gateway, enabling safety and content filtering on model serving endpoints. Sub-feature of AI Gateway.",PUBLIC_PREVIEW,-,-,Docs,2026-02-09
AI and machine learning,ai_parse_document(),https://docs.databricks.com/aws/en/sql/language-manual/functions/ai_parse_document,The ai_parse_document() function invokes a state-of-the-art generative AI model from Databricks Foundation Model APIs to extract structured content from unstructured documents.,PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
AI and machine learning,ai_query() for Custom Models and External Models,https://docs.databricks.com/en/large-language-models/how-to-ai-query.html,"Allows ai_query() to connect with Custom Model and External Model endpoints (querying Foundation Model APIs is enabled by default). When enabled, ai_query() used with external models could result in data egress to external model providers. See the documentation for region availability and DBSQL requirements for this functionality.",PUBLIC_PREVIEW,-,High — enables data egress to external model providers,Workspace,2026-02-05
AI and machine learning,Batch inference,https://learn.microsoft.com/en-gb/azure/databricks/large-language-models/batch-inference-pipelines,This page shows how you can integrate AI Functions into other Databricks data and AI products to build complete batch inference pipelines.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
AI and machine learning,Microsoft Teams agent integration,https://learn.microsoft.com/en-gb/azure/databricks/generative-ai/agent-framework/teams-agent,"This page shows how to integrate AI agents with Microsoft Teams using OAuth ""On Behalf Of"" authentication. This integration lets your Databricks agents interact with users through Microsoft Teams while maintaining secure, user-delegated access to Dat...",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
AI and machine learning,External Tool Calling for Agents,https://docs.databricks.com/en/generative-ai/agent-framework/external-connection-tools.html,Create AI agent tools that can connect to external applications with an API using HTTP requests,PUBLIC_PREVIEW,-,High — agent tools make HTTP calls to external APIs,Workspace,2026-02-05
AI and machine learning,Feature management,https://learn.microsoft.com/en-gb/azure/databricks/machine-learning/feature-store/migrate-from-online-tables,This page describes how to migrate your existing online tables. You can migrate to the following:,PUBLIC_PREVIEW,-,-,Workspace,2026-02-08
AI and machine learning,Foundation Model Fine-tuning,https://learn.microsoft.com/en-gb/azure/databricks/large-language-models/foundation-model-training/,"This feature is in Public Preview in the following regions: centralus, eastus, eastus2, northcentralus, and westus.",PUBLIC_PREVIEW (5 regions),-,-,Docs,2026-02-08
AI and machine learning,LLM integrations overview,https://learn.microsoft.com/en-gb/azure/databricks/large-language-models/,Azure Databricks makes it simple to access and build off of publicly available large language models. Databricks Runtime for Machine Learning includes libraries like Hugging Face Transformers and LangChain that allow you to integrate existing pre-tra...,GA,-,-,Docs,2026-02-08
AI and machine learning,Legacy inference tables,https://learn.microsoft.com/en-gb/azure/databricks/machine-learning/model-serving/enable-model-serving-inference-tables,"This article describes the legacy inference table experience, which is only relevant for certain provisioned throughput and custom model serving endpoints.",GA,-,-,Docs,2026-02-08
AI and machine learning,Managed MCP Servers,https://learn.microsoft.com/en-gb/azure/databricks/generative-ai/mcp/managed-mcp,"Databricks managed MCP (Model Context Protocol) servers enable your AI agents to access data and tools governed in Databricks, with data governance and permissions enforced out of the box",PUBLIC_PREVIEW,-,Medium — MCP servers access governed data on agent's behalf,Workspace,2026-02-05
AI and machine learning,Connect clients to MCP servers,https://learn.microsoft.com/en-gb/azure/databricks/generative-ai/mcp/connect-external-services,"Connect non-Databricks (external) clients, AI assistants, and IDEs that support Model Context Protocol (MCP) to Databricks MCP servers. This provides access to Databricks data and tools directly in your development environment.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
AI and machine learning,sparkdl.xgboost (deprecated),https://learn.microsoft.com/en-gb/azure/databricks/machine-learning/train-model/sparkdl-xgboost,"sparkdl.xgboost is deprecated starting with Databricks Runtime 12.0 ML, and is removed in Databricks Runtime 13.0 ML and above.",GA,-,-,Docs,2026-02-08
AI and machine learning,Models in Unity Catalog: Deployment Jobs,https://learn.microsoft.com/en-us/azure/databricks/mlflow/deployment-job,"Deployment jobs allow you to manage the model lifecycle by automating tasks like evaluation, approval, and deployment whenever a new model version is created, integrating seamlessly with Unity Catalog models and Databricks Jobs. These jobs simplify the setup of model deployment pipelines, incorporate human-in-the-loop approvals, and provide governed workflows with clear visibility into progress and historical context for each model version.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
AI and machine learning,Serverless forecasting,https://learn.microsoft.com/en-gb/azure/databricks/machine-learning/train-model/serverless-forecasting,This article shows you how to run a serverless forecasting experiment using the Mosaic AI Model Training UI. Mosaic AI Model Training - forecasting simplifies forecasting time-series data by automatically selecting the best algorithm and hyperparamet...,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
AI and machine learning,Storage Optimized Vector Search,https://docs.databricks.com/en/generative-ai/vector-search#endpoint-options,"This preview introduces Storage Optimized Vector Search. Storage Optimized Vector Search is engineered from the ground up to support massive-scale use cases, with the capacity to handle tens of billions of embeddings. It delivers a dramatically lower price-per-vector cost and significantly enhances ingestion performance, offering a powerful alternative to the Standard Vector Search product for demanding, large-scale applications.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
AI and machine learning,Synthetic Agent Evaluation,https://docs.databricks.com/en/generative-ai/agent-evaluation/synthesize-evaluation-set.html,Synthetically generate a high-quality evaluation set for measuring the quality of your agent.,PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
AI and machine learning,Build dashboards with MLflow metadata,https://learn.microsoft.com/en-gb/azure/databricks/mlflow/build-dashboards,"Using MLflow metadata in system tables, you can build dashboards to analyze your MLflow experiments and runs from the entire workspace. Using the existing MLflow UI and REST APIs for these tasks would require extensive, time-consuming iteration.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
AI and machine learning,Foundation Model Fine-tuning tutorial,https://learn.microsoft.com/en-gb/azure/databricks/large-language-models/foundation-model-training/fine-tune-run-tutorial,"This feature is in Public Preview in the following regions: centralus, eastus, eastus2, northcentralus, and westus.",PUBLIC_PREVIEW (5 regions),-,-,Docs,2026-02-08
AI and machine learning,vector_search() AI function,https://learn.microsoft.com/en-gb/azure/databricks/vector-search/query-vector-search,"This article describes how to query a vector search index, including how to use filters and reranking. For example notebooks illustrating how to create and query vector search endpoints and indexes, see Vector search example notebooks.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
AI and machine learning,Enable Qwen Model Family Endpoints,https://docs.databricks.com/aws/en/machine-learning/foundation-model-apis/supported-models#qwen3-next-instruct,This preview enables all Qwen endpoints on model serving surfaces.,BETA,-,Low,Workspace,2026-02-05
AI and machine learning,Managed MLflow Prompt Registry,https://learn.microsoft.com/en-us/azure/databricks/mlflow3/genai/prompt-version-mgmt/prompt-registry/create-and-edit-prompts,"Managed MLflow Prompt Registry on Databricks is a powerful tool that streamlines prompt engineering and management in your Generative AI (GenAI) applications. It enables you to version, track, and reuse prompts across your organization, helping maintain consistency and improving collaboration in prompt development.  The Prompt Registry also enables you to optimize prompts through a native integration with DSPy, delivering higher quality while minimizing time spent on manual prompt engineering.",BETA,-,Low,Workspace,2026-02-05
AI and machine learning,MLflow API Reference,https://learn.microsoft.com/en-gb/azure/databricks/mlflow3/genai/api-reference,"This page provides an index of important MLflow APIs used in GenAI applications, with direct links to the official MLflow documentation. MLflow features marked as ""Databricks only"" are only available on Databricks-managed MLflow. Quick links",BETA,-,-,Docs,2026-02-08
AI and machine learning,Mosaic AI Agent Bricks Preview,https://learn.microsoft.com/en-us/azure/databricks/generative-ai/ai-builder/,"Mosaic AI Agent Bricks enables you to build and optimize domain-specific agent systems. Simply select your problem, and Agent Bricks will run optimizations to improve quality and cost, generating a deployable endpoint on Databricks. Additionally, Agent Bricks provides automated evaluation and recommendations to refine your agent systems performance. Enabling this flag will also enable ai_parse_document function; however, for the regions where Agent Bricks is not available, you will only get access to ai_parse_document without Agent Bricks enabled.",BETA,-,"Medium — AI agent bricks deploy endpoints, review access controls",Workspace,2026-02-05
AI and machine learning,OpenTelemetry on Databricks,https://learn.microsoft.com/en-us/azure/databricks/mlflow3/genai/tracing/trace-unity-catalog,"Enables ingestion of OpenTelemetry data into Unity Catalog managed Delta tables for MLflow Tracing. For direct ingestion via OTLP endpoints, see https://docs.google.com/document/d/1_cMNMbepAy2rt0QuVlSKgWR7bLSvXmVar-BSIdvvAKY.",BETA,-,Low,Workspace,2026-02-05
AI and machine learning,Production Monitoring for MLflow,https://docs.databricks.com/aws/en/mlflow3/genai/eval-monitor/production-monitoring,"This beta enables monitoring of any Generative AI app or agent deployed outside of Databricks OR on Databricks using MLflow 3.0. It provides developers with tools to track both performance metrics (latency, request volume, errors) and quality metrics (accuracy, correctness, compliance), allowing them to detect drift or regressions via LLM-based evaluations on production traffic. Developers can also deep dive into individual requests for debugging and improvement purposes, and export real-world logs into evaluation sets to drive continuous enhancements of their Generative AI applications.",BETA,-,Low,Workspace,2026-02-05
AI and machine learning,Serverless GPU compute (Beta),https://learn.microsoft.com/en-gb/azure/databricks/compute/serverless/gpu,This feature is in Beta. Workspace admins can control access to this feature from the Previews page. See Manage Azure Databricks previews.,BETA,-,-,Docs,2026-02-08
AI and machine learning,Vector Search Full Text,https://docs.databricks.com/aws/en/generative-ai/create-query-vector-search#query-a-vector-search-endpoint,"When enabled, users can run full-text search queries directly on indices. This bypasses ANN entirely and is especially valuable in scenarios where precise keyword matching is required.",BETA,-,Low,Workspace,2026-02-05
Administration,Jobs system tables,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/jobs,The lakeflow schema was previously known as workflow. The content of both schemas is identical.,GA,-,-,Docs,2026-02-08
Administration,Serverless Workspaces,https://learn.microsoft.com/en-us/azure/databricks/admin/workspace/serverless-workspaces,"Serverless workspaces are Databricks-managed workspaces that come pre-configured with Unity Catalog, serverless compute and default storage, providing a lightweight, fast-to-deploy full SaaS workspace experience.",GA,-,Medium — serverless workspaces shift control to Databricks-managed infra,Account,2026-02-05
Administration,Cluster Log Delivery to UC Volumes,https://learn.microsoft.com/en-us/azure/databricks/compute/configure#cluster-log-delivery,"Allows users to configure a classic compute cluster’s cluster log delivery to a UC volume path through UI or API. Cluster logs for the Spark driver node, worker nodes and events will be delivered to the configured volume path.",GA_SOON,-,Low,Workspace,2026-02-05
Administration,Audit log system table,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/audit-logs,"This article outlines the audit log table schema and has sample queries you can use with the audit log system table to answer common account activity questions. For information on audit log events, see Diagnostic log reference.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Administration,Budget Policy,https://learn.microsoft.com/en-us/azure/databricks/admin/usage/budget-policies,"Allow billing admins to enforce tagging requirements across serverless workloads such as workflows, notebooks, DLT pipelines, model-serving, and Databrick Apps.",PUBLIC_PREVIEW,-,Low,Account,2026-02-05
Administration,Clean room system table,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/clean-rooms,The clean room events table records actions taken by you or your collaborators on clean rooms in your account. This table includes regional data from across your account.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Administration,Data classification system tables,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/data-classification,This page outlines the data classification results table schema and includes sample queries. The table stores detections for sensitive data classes at the column level across enabled catalogs in your metastore.,BETA,-,-,Docs,2026-02-08
Administration,Data quality monitoring system tables reference,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/data-quality-monitoring,"This page outlines the data quality monitoring results system table schema and includes sample queries. The table stores results of freshness and completeness checks, as well as downstream impact and root cause analysis, across all tables enabled for...",BETA,-,-,Docs,2026-02-08
Administration,Databricks Assistant system table,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/assistant,This page includes a schema reference of the Databricks Assistant events system table and an example that uses the data in a dashboard.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Administration,Immutable external groups,https://learn.microsoft.com/en-us/azure/databricks/admin/users-groups/groups#account-vs-workspace-group,"External groups are groups that are created using a SCIM provisioning connector. When enabled, external groups can not be updated using the Databricks UI.",PUBLIC_PREVIEW,-,Low,Account,2026-02-05
Administration,Marketplace system tables,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/marketplace,This page provides a reference on how to use system tables to help monitor your Databricks Marketplace selling process. Marketplace system tables live in the system.marketplace schema.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Administration,MLflow Metadata System Table,https://learn.microsoft.com/en-us/azure/databricks/admin/system-tables/mlflow,"Enables the system.mlflow schema, which contains metadata recorded for MLflow experiments and runs. This preview no longer requires enrollment as the feature is now in public preview with the schema available to customers by default, please see the documentation for how account admins can share schema access with users.",PUBLIC_PREVIEW,-,Low,Account,2026-02-05
Administration,Network access system table,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/network,"The network access events tables record events where network access is denied. Each row represents an individual event, such as a blocked outbound request to an external domain or a blocked inbound request from a restricted IP.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Administration,Predictive optimization system table,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/predictive-optimization,"To have access to this table, your region must support predictive optimization. See Azure Databricks regions.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Administration,Query History System Table,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/query-history,"Enables the system.query.history table, which contains performance insights for all your queries. Note that you must additionally enable the schema ""query"" as described in the documentation.",PUBLIC_PREVIEW,-,Low,"Account, Docs",2026-02-08
Administration,SQL warehouse events system table,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/warehouse-events,SCALED_UP: A new cluster was added to the warehouse. SCALED_DOWN: A cluster was removed from the warehouse. STOPPING: The warehouse is in the process of stopping. RUNNING: The warehouse is actively running.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Administration,SQL warehouses system table,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/warehouses,Use the warehouses system table to monitor and manage the SQL warehouses in your workspaces. Each row is a snapshot of the SQL warehouse properties at that moment. A new snapshot is created when the properties change. Table path: system.compute.warehouses.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Administration,System tables overview,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/,This article explains the concept of system tables in Azure Databricks and highlights resources you can use to get the most out of your system tables data.,GA,-,-,Docs,2026-02-08
Administration,Workspaces system table,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/workspaces,"This page explains how to use the workspaces system table to monitor workspaces in your Azure Databricks account. Each row in the table represents the latest known state of an active workspace in your account, including metadata and lifecycle status....",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Administration,Diagnostic logs,https://learn.microsoft.com/en-gb/azure/databricks/admin/account-settings/audit-logs,This article provides you with a comprehensive reference of audit log services and events. The availability of these services depends on how you access the logs:,GA,-,-,Docs,2026-02-08
Administration,Diagnostic logs > Alerts audit events,https://learn.microsoft.com/en-gb/azure/databricks/admin/account-settings/audit-logs,Audit log events for SQL Alerts (alertsV2 service). Sub-feature of Diagnostic logs.,BETA,-,-,Docs,2026-02-09
Administration,Diagnostic logs > Access request destination events,https://learn.microsoft.com/en-gb/azure/databricks/admin/account-settings/audit-logs,Audit log events for access request destinations (accessRequestDestination service). Sub-feature of Diagnostic logs.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Administration,Diagnostic logs > Account Access Control API events,https://learn.microsoft.com/en-gb/azure/databricks/admin/account-settings/audit-logs,Audit log events for account-level access control operations (accountsAccessControl service). Sub-feature of Diagnostic logs.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Administration,Diagnostic logs > Service principal credentials events,https://learn.microsoft.com/en-gb/azure/databricks/admin/account-settings/audit-logs,Audit log events for service principal credential management (servicePrincipalCredentials service). Sub-feature of Diagnostic logs.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Administration,Diagnostic logs > Delta Sharing Iceberg client events,https://learn.microsoft.com/en-gb/azure/databricks/admin/account-settings/audit-logs,Audit log events for Delta Sharing Iceberg client access (deltaSharingIcebergClient service). Sub-feature of Diagnostic logs.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Administration,Zerobus system tables reference,https://learn.microsoft.com/en-gb/azure/databricks/admin/system-tables/zerobus-ingest,"This article is a reference for the zerobus system tables, which track Zerobus Ingest activity in your workspace. These tables include your account records from all workspaces in your same region.",BETA,-,-,Docs,2026-02-08
Apps,Databricks Apps – Configure App Compute Size,https://learn.microsoft.com/en-us/azure/databricks/dev-tools/databricks-apps/compute-size,Allows app developers to select predefined compute sizes for Databricks Apps. This feature enables building apps that require more CPU or memory to handle larger workloads.,GA,-,Low,Workspace,2026-02-05
Apps,App tags,https://learn.microsoft.com/en-gb/azure/databricks/dev-tools/databricks-apps/tags,Use tags to organize and categorize Databricks apps for easier management. Databricks Apps also support certification and deprecation system tags to indicate trust or lifecycle status.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Apps,Databricks Apps - On-Behalf-Of User Authorization,https://docs.databricks.com/dev-tools/databricks-apps/app-development#-using-the-databricks-apps-authorization-model,Allows the Databricks App to act on behalf of the app user. This enhancement allows the app to honor the user's access permissions defined in Unity Catalog and in Databricks Workspace.,PUBLIC_PREVIEW,-,"High — apps act on behalf of user, broad permission scope",Workspace,2026-02-05
Business intelligence,Embed a dashboard,https://learn.microsoft.com/en-gb/azure/databricks/dashboards/embedding/,This page shows how to embed an AI/BI dashboard in an external website or application. Work with published dashboards Only published dashboards can be embedded into external applications.,GA,-,-,Docs,2026-02-08
Business intelligence,Dashboard embedding for external users,https://learn.microsoft.com/en-gb/azure/databricks/dashboards/embedding/,Embed published dashboards for viewers outside your Databricks workspace. Sub-feature of dashboard embedding.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Business intelligence,Dashboard and Genie usage auditing,https://learn.microsoft.com/en-gb/azure/databricks/ai-bi/admin/audit,"This article has sample queries that workspace admins can use to monitor activity associated with dashboards and Genie spaces. All queries access the audit logs table, which is a system table that stores records for all audit events from workspaces i...",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Business intelligence,Custom calculations,https://learn.microsoft.com/en-gb/azure/databricks/dashboards/custom-calculations/,Custom calculations let you define dynamic metrics and transformations without modifying dataset queries. This page explains how to use custom calculations in AI/BI dashboards.,GA,-,-,Docs,2026-02-08
Business intelligence,Custom calculations > Metric view integration,https://learn.microsoft.com/en-gb/azure/databricks/dashboards/custom-calculations/,Define custom calculations on top of a dataset created by a metric view. Sub-feature of Custom calculations.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Business intelligence,Dashboard settings,https://learn.microsoft.com/en-gb/azure/databricks/dashboards/settings,"This page explains how to customize dashboard settings and themes to match your organization's branding, improve readability, and ensure consistent data presentation across different regions and languages.",GA,-,-,Docs,2026-02-08
Business intelligence,Dashboards,https://learn.microsoft.com/en-gb/azure/databricks/dashboards/,"You can use dashboards to build data visualizations and share reports with your team. AI/BI dashboards feature AI-assisted authoring, an enhanced visualization library, and a streamlined configuration experience so that you can quickly transform data...",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Business intelligence,Dashboards with Genie spaces,https://learn.microsoft.com/en-gb/azure/databricks/dashboards/genie-spaces,"Published dashboards include a Genie space by default to allow business users to explore data using natural language. A Genie space is a no-code interface that provides an Ask Genie button on published dashboards, allowing viewers to chat with the da...",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Business intelligence,Genie - Upload File,https://docs.databricks.com/en/genie/file-upload,"AI/BI Genie now supports a File Upload functionality in this preview. This feature enables users to enhance their analytics capabilities by blending data from the Unity Catalog with their own personal files. Users can interact with their combined datasets using natural language queries, receiving insightful answers quickly and intuitively. Supported file formats for this preview are CSV and Excel files. To get started, turn this preview on and drag files into any Genie space conversation.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Business intelligence,Manage datasets,https://learn.microsoft.com/en-gb/azure/databricks/dashboards/datasets,"This article explains how to create and manage dashboard datasets using the dataset editor in an AI/BI dashboard. Define datasets To define or access existing datasets, click the Data tab near the upper-left corner of your dashboard.",GA,-,-,Docs,2026-02-08
Business intelligence,Manage datasets > Metric view as data source,https://learn.microsoft.com/en-gb/azure/databricks/dashboards/datasets,Use a metric view as a data source for dashboard datasets. Sub-feature of Manage datasets.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Business intelligence,Manage datasets > Export as metric view,https://learn.microsoft.com/en-gb/azure/databricks/dashboards/datasets,Export a dashboard dataset as a metric view for centralized business logic. Sub-feature of Manage datasets.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Business intelligence,Sample Data Exploration with Assistant,https://learn.microsoft.com/en-us/azure/databricks/discover/database-objects#natural-language,"Generate queries in the sample data page using natural language. Describe what you want to see, and the AI creates SQL queries you can run directly or open in the editor.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Business intelligence,Support Dashboards in Git Folder,https://docs.databricks.com/en/dashboards/git-support.html,Enable version control for Dashboards within Git Folder,PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Business intelligence,Genie Research Agent,https://learn.microsoft.com/en-us/azure/databricks/genie/research-agent,The Genie Research Agent provides deeper data insights and answers complex business questions using multi-step reasoning and hypothesis investigation.,BETA,-,Medium — multi-step AI agent reasons over your data,Workspace,2026-02-05
Business intelligence,Use the dashboard authoring agent,https://learn.microsoft.com/en-gb/azure/databricks/dashboards/dashboard-agent,This feature is in Beta. Workspace admins can control access to this feature from the Previews page. See Manage Azure Databricks previews.,BETA,-,-,Docs,2026-02-08
Compute,Dedicated compute,https://learn.microsoft.com/en-gb/azure/databricks/compute/dedicated-overview,This page provides an overview of dedicated compute access mode. What is dedicated compute? Dedicated compute is compute configured with dedicated access mode.,GA,-,-,Docs,2026-02-08
Compute,Dedicated compute group access,https://learn.microsoft.com/en-gb/azure/databricks/compute/dedicated-overview,Allow groups to use dedicated compute access mode. Sub-feature of dedicated compute.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Compute,Default warehouse setting,https://learn.microsoft.com/azure/databricks/compute/sql-warehouse/create#set-a-user-level-default-warehouse,"The default warehouse feature allows Databricks workspace admins to define a default SQL warehouse that is pre-selected for users across SQL authoring surfaces, including Catalog Explorer, SQL Editor, Dashboards, Alerts, and Genie. Users can optionally override this default to set a customer default warehouse for themselves.",GA,-,Low,Workspace,2026-02-05
Compute,Libraries,https://learn.microsoft.com/en-gb/azure/databricks/libraries/notebooks-python-libraries,"Notebook-scoped libraries let you create, modify, save, reuse, and share custom Python environments that are specific to a notebook.",GA,-,-,Docs,2026-02-08
Compute,Install libraries from UC volumes with %pip,https://learn.microsoft.com/en-gb/azure/databricks/libraries/notebooks-python-libraries,Install Python libraries from Unity Catalog volumes using %pip in notebooks. Sub-feature of notebook-scoped libraries.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Compute,High memory option for serverless notebooks & jobs,https://docs.databricks.com/compute/serverless/notebooks.html#high-memory,This preview brings the ability to increase available memory for serverless notebooks and jobs to help customers avoid out-of-memory crashes.,PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Compute,Workspace base environments for serverless compute,https://learn.microsoft.com/en-us/azure/databricks/admin/workspace-settings/base-environment,Workspace base environments ensure that users automatically have a predefined environment version and set of Python packages available in their notebooks.,PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Compute,Serverless Scala and Java Jobs,https://docs.databricks.com/aws/en/jobs/jar,"Deploy Scala and Java jobs as Jars on serverless compute with faster startup, auto-scaling, and no cluster management",BETA,-,Low,Workspace,2026-02-05
Data engineering,Selective overwrite,https://learn.microsoft.com/en-gb/azure/databricks/delta/selective-overwrite,Azure Databricks leverages Delta Lake functionality to support two distinct options for selective overwrites:,GA,-,-,Docs,2026-02-08
Data engineering,Configure jobs,https://learn.microsoft.com/en-gb/azure/databricks/jobs/configure-job,"You can create and run a job using the Jobs UI, or developer tools such as the Databricks CLI or the REST API. Using the UI or API, you can repair and rerun a failed or canceled job.",GA,-,-,Docs,2026-02-08
Data engineering,Streaming observability for jobs,https://learn.microsoft.com/en-gb/azure/databricks/jobs/configure-job,Streaming metrics and observability features for Structured Streaming jobs. Sub-feature of Configure jobs.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Data engineering,Configure pipelines,https://learn.microsoft.com/en-gb/azure/databricks/ldp/serverless,This article describes configurations for serverless pipelines. Databricks recommends developing new pipelines using serverless. Some workloads might require configuring classic compute or working with the legacy Hive metastore.,GA,-,-,Docs,2026-02-08
Data engineering,@materialized_view decorator,https://learn.microsoft.com/en-gb/azure/databricks/ldp/developer/ldp-python-ref-materialized-view,"The @materialized_view decorator can be used to define materialized views in a pipeline. To define a materialized view, apply @materialized_view to a query that performs a batch read against a data source. Syntax",GA,-,-,Docs,2026-02-08
Data engineering,@materialized_view row_filter parameter,https://learn.microsoft.com/en-gb/azure/databricks/ldp/developer/ldp-python-ref-materialized-view,The row_filter parameter for @materialized_view to apply row-level filters in pipelines. Sub-feature of @materialized_view.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Data engineering,@materialized_view refresh_policy parameter,https://learn.microsoft.com/en-gb/azure/databricks/ldp/developer/ldp-python-ref-materialized-view,The refresh_policy parameter for @materialized_view to control refresh scheduling in pipelines. Sub-feature of @materialized_view.,BETA,-,-,Docs,2026-02-09
Data engineering,Default Python package repositories in clusters created via API,https://learn.microsoft.com/en-us/azure/databricks/admin/workspace-settings/default-python-packages,Apply the default Python package repositories in clusters created via API. The changes of configurations apply to newly created clusters and existing clusters upon restart.,GA_SOON,-,Medium — alters package resolution on API clusters,Workspace,2026-02-05
Data engineering,Default Python package repositories in clusters created via UI,https://learn.microsoft.com/en-us/azure/databricks/admin/workspace-settings/default-python-packages,Apply the default Python package repositories in clusters created via UI. The changes of configurations apply to newly created clusters and existing clusters upon restart.,GA_SOON,-,Medium — alters package resolution on UI clusters,Workspace,2026-02-05
Data engineering,Default Python package repositories in Spark Declarative Pipelines,https://learn.microsoft.com/en-us/azure/databricks/admin/workspace-settings/default-python-packages,Default Python package repositories in serverless and classic Spark Declarative Pipelines (SDP). The changes of configurations apply to new pipeline runs.,GA_SOON,-,Medium — alters package resolution in pipelines,Workspace,2026-02-05
Data engineering,Data quality monitoring with anomaly detection (workspace level),https://docs.databricks.com/aws/en/data-quality-monitoring/anomaly-detection,"This feature allows you to be alerted on data quality anomalies (e.g. freshness, completeness) for your tables. By learning the behaviors of each table and intelligently setting thresholds, the feature allows you to easily alert on data quality incidents across all your important tables. Currently, the feature is limited to freshness monitoring and is a library you call in a notebook, but will soon also include completeness (row count) monitoring. The table health information will also be published in Unity Catalog so data consumers know if a table has an ongoing data quality incident.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Data engineering,Enables remote query table-valued function (remote_query).,https://docs.databricks.com/aws/en/query-federation/remote-queries,Function allows users to execute query in remote engine syntax using credentials from a Unity Catalog connection. Function is available on Databricks Runtime 17.3 or above.,PUBLIC_PREVIEW,-,Medium — executes queries on remote engines via credentials,Workspace,2026-02-05
Data engineering,Join Pushdown for Federated Queries,https://docs.databricks.com/aws/en/query-federation/performance-recommendations#join-pushdown-in-lakehouse-federation,"Enables automatic pushdown of join operations to remote databases when executing federated queries through Lakehouse Federation. When enabled, Databricks pushes inner, left, and right joins between tables from the same JDBC datasource (Oracle, PostgreSQL, MySQL, SQL Server, Teradata) directly to the remote database engine, reducing data transfer and improving query performance. This feature is available on Databricks Runtime 17.2 and above.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Data engineering,Lakeflow Connect Column Selection for Database Sources,https://learn.microsoft.com/en-us/azure/databricks/ingestion/lakeflow-connect/column-selection,Enable column selection for Lakeflow Connects SQL Server connector. Available only via API.,PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Data engineering,Lakeflow Connect for Dynamics 365,https://learn.microsoft.com/en-us/azure/databricks/ingestion/lakeflow-connect/d365-source-setup,Ingest Dynamics 365 data via Dataverse with a simple and efficient connector. Available via API or UI.,PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Data engineering,Lakeflow Connect for Netsuite,https://learn.microsoft.com/en-us/azure/databricks/ingestion/lakeflow-connect/netsuite-source-setup,Ingest NetSuite data with a simple and efficient connector. Available via API only.,PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Data engineering,Lakeflow Pipelines Editor,https://learn.microsoft.com/en-us/azure/databricks/dlt/dlt-multi-file-editor,"Purpose-built IDE for declarative data pipelines. Designed to support everything you need for building pipelines in one place: code-first authoring, folder-based organization, selective execution, data previews, and pipeline graphs. Integrated with the Databricks Platform, supporting version control, code reviews, and scheduling.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Data engineering,Monitor Lakeflow pipelines in the UI,https://learn.microsoft.com/en-gb/azure/databricks/ldp/monitoring-ui,This section describes using built-in monitoring and observability features for Lakeflow Spark Declarative Pipelines in the Azure Databricks user interface. These features support tasks such as:,GA,-,-,Docs,2026-02-08
Data engineering,Clone Parquet and Iceberg tables to Delta Lake,https://learn.microsoft.com/en-gb/azure/databricks/ingestion/data-migration/clone-parquet,You can use Azure Databricks clone functionality to incrementally convert data from Parquet or Apache Iceberg data sources to managed or external Delta tables.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Data engineering,Monitor materialized views in Databricks SQL,https://learn.microsoft.com/en-gb/azure/databricks/ldp/dbsql/materialized-monitor,"This article describes how to monitor and query refresh data about a materialized view in Databricks SQL. View the details of a single materialized view You can view the details of a single materialized view by using the Catalog Explorer, or programm...",GA,-,-,Docs,2026-02-08
Data engineering,Power BI task type,,"The Power BI task type in Databricks Workflows allows users to keep Power BI semantic models up-to-date with source data in Unity Catalog. The task can sync table metadata, evolving schemas, and primary/foreign key relationships. It works for DirectQuery and Import mode at the table level, allowing you to define composite models.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Data engineering,SFTP Connector,https://learn.microsoft.com/azure/databricks/ingestion/sftp,Ingest files from SFTP server using Auto Loader. Requires DBR 17.3+.,PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Data engineering,Unified Runs List,https://docs.google.com/document/d/1ga9tv2ctn6-OtzgkomqbaJe8BTPVsYb_UgZOXEJnJ_M,"You can now view all of your Jobs and Pipeline executions in the updated Runs list. Track all of your pipeline executions in one place and filter by status, time, run-as user, and error codes in real time. Spot trends using the visualization and summary of the current top five error codes.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Data engineering,Custom JDBC on UC Compute,https://docs.databricks.com/aws/en/connect/jdbc-connection,"This feature enables users to connect to data sources using a custom JDBC driver through the Spark Data Source API. The new UC Connection of type JDBC, runs a user-provided JDBC driver powered by Lakeguard isolation on UC-supported compute: serverless, standard, and dedicated clusters with DBR 17.3 or higher.",BETA,-,Medium — custom JDBC drivers run user-provided code,Workspace,2026-02-05
Data engineering,dbt platform task,https://learn.microsoft.com/en-us/azure/databricks/jobs/dbt-platform,The dbt platform task lets you run your dbt platform jobs as part of existing databricks workflows,BETA,-,Low,Workspace,2026-02-05
Data engineering,Excel File Format Support,https://learn.microsoft.com/en-us/azure/databricks/query/formats/excel,"Read Excel files using Spark batch and streaming APIs including Auto Loader, read_files, spark.read and COPY INTO. Available in DBR17.1+",BETA,-,Low,Workspace,2026-02-05
Data engineering,Lakeflow Connect for Confluence,https://learn.microsoft.com/en-gb/azure/databricks/ingestion/lakeflow-connect/confluence-source-setup,Ingest from Confluence with a simple and efficient connector,BETA,-,Low,Workspace,2026-02-05
Data engineering,Lakeflow Connect for Google Drive,https://learn.microsoft.com/en-us/azure/databricks/ingestion/google-drive,Ingest from Google Drive with a simple and efficient connector. **Requires DBR 17.3+**,BETA,-,Low,Workspace,2026-02-05
Data engineering,Lakeflow Connect for Jira,https://learn.microsoft.com/en-gb/azure/databricks/ingestion/lakeflow-connect/jira-source-setup,Ingest Jira data with a simple and efficient connector. Available via API for both Jira Cloud and on premise instances.,BETA,-,Low,Workspace,2026-02-05
Data engineering,Lakeflow Connect for Meta Ads,https://learn.microsoft.com/en-gb/azure/databricks/ingestion/lakeflow-connect/meta-ads-source-setup,Ingest Meta Ads data with a simple and efficient connector.,BETA,-,Low,Workspace,2026-02-05
Data engineering,Lakeflow Connect for Sharepoint,https://learn.microsoft.com/en-us/azure/databricks/ingestion/sharepoint,Ingest Sharepoint data with a simple and efficient connector. Available via API.,BETA,-,Low,Workspace,2026-02-05
Data engineering,Lakeflow Connect for Zendesk,https://learn.microsoft.com/en-gb/azure/databricks/connect/managed-ingestion,Ingest Zendesk Support data with a managed ingestion connector.,BETA,-,-,Docs,2026-02-09
Data governance,Access control in Unity Catalog,https://learn.microsoft.com/en-gb/azure/databricks/data-governance/unity-catalog/access-control,"This page has an overview of access control in Unity Catalog, including privileges, policies, and data-level controls. Layers of access control Access control in Unity Catalog is built on the following complementary models:",GA,-,-,Docs,2026-02-08
Data governance,Data governance overview,https://learn.microsoft.com/en-gb/azure/databricks/data-governance/,"Data governance is a framework of policies, processes, roles, and technical controls that ensures your organization's data is secure, trustworthy, and used responsibly throughout its lifecycle.",GA,-,-,Docs,2026-02-08
Data governance,Attribute Based Access Control,https://docs.databricks.com/en/data-governance/unity-catalog/abac,"Attribute Based Access Control (ABAC) in Unity Catalog enables scalable, fine-grained data governance by dynamically enforcing access control policies based on tags and user principals. Administrators can define policies once at the catalog, schema, or table level, using tags to selectively apply row filters or column masks without manually configuring individual securables, streamlining governance across the Lakehouse.",PUBLIC_PREVIEW,-,Medium — policy misconfiguration can leak rows/columns,Account,2026-02-05
Data governance,Attribute Based Access Control in Delta Sharing,https://learn.microsoft.com/en-us/azure/databricks/delta-sharing/create-share#abac,This feature allows privileged users on the provider side to share ABAC-enabled assets.,PUBLIC_PREVIEW,-,Medium — ABAC sharing exposes data to external recipients,Account,2026-02-05
Data governance,Data Classification,https://learn.microsoft.com/en-gb/azure/databricks/data-governance/unity-catalog/data-classification,This preview allows you to classify and review sensitive data across your entire catalog. This version delivers higher quality detection using a LLM-powered classification engine hosted by Databricks. Customer data will not be retained or shared with Databricks or any third parties.,PUBLIC_PREVIEW,-,Low,"Workspace, Docs",2026-02-08
Data governance,Flag certified and deprecated data,https://learn.microsoft.com/en-gb/azure/databricks/data-governance/unity-catalog/certify-deprecate-data,"This page shows how to apply system tags to objects to mark them as certified or deprecated. Certification status system tag The certified status system tag allows users to label objects, such as catalogs, schemas, tables, dashboards, Genie spaces, a...",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Data governance,Governed Tags,https://learn.microsoft.com/en-gb/azure/databricks/admin/governed-tags/,Tag policies are used to control which users can assign certain tags and which values these users can select from when applying the governed tags. Governed tags are applicable to Unity Catalog objects and can be referenced in attribute based access control policies.,PUBLIC_PREVIEW,-,Low,"Account, Docs",2026-02-08
Data governance,Manage privileges,https://learn.microsoft.com/en-gb/azure/databricks/data-governance/unity-catalog/manage-privileges/,"This page explains how to control access to data and other objects in Unity Catalog. To learn about how this model differs from access control in the Hive metastore, see Work with the legacy Hive metastore alongside Unity Catalog.",GA,-,-,Docs,2026-02-08
Data governance,Manage privileges > Access requests and destination configuration,https://learn.microsoft.com/en-gb/azure/databricks/data-governance/unity-catalog/manage-privileges/,"Users can request access to Unity Catalog objects via Catalog Explorer, search, or direct links. Destinations include email, Slack, Teams, webhooks, or redirect URL. Sub-feature of Manage privileges.",PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Data governance,Bring your own lineage,https://learn.microsoft.com/en-gb/azure/databricks/data-governance/unity-catalog/external-lineage,This page describes how to update data lineage to include external assets and workflows that are run outside of Azure Databricks. Unity Catalog automatically captures runtime data lineage across queries that are run on Azure Databricks.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Data guides,Connect to managed ingestion sources (Lakeflow Connect),https://learn.microsoft.com/en-gb/azure/databricks/connect/managed-ingestion,Learn how to create connections in Catalog Explorer that store authentication details for Lakeflow Connect managed ingestion sources.,GA,-,-,Docs,2026-02-08
Data guides,Tag database objects,https://learn.microsoft.com/en-gb/azure/databricks/database-objects/tags,This page shows how to apply tags to Unity Catalog securable objects. Tags are attributes that include keys and optional values that you can use to organize and categorize securable objects in Unity Catalog.,GA,-,-,Docs,2026-02-08
Data guides,Access data using external systems,https://learn.microsoft.com/en-gb/azure/databricks/external-access/admin,Azure Databricks provides access to Unity Catalog tables using the Unity REST API and Apache Iceberg REST catalog. A metastore admin must enable external data access for each metastore you need to access externally.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Data guides,XML file format support,https://learn.microsoft.com/en-gb/azure/databricks/query/formats/xml,"This article describes how to read and write XML files. Extensible Markup Language (XML) is a markup language for formatting, storing, and sharing data in textual format.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Data sharing,Delta Sharing overview,https://learn.microsoft.com/en-gb/azure/databricks/delta-sharing/,"This page introduces Delta Sharing in Azure Databricks, the secure data sharing platform that lets you share data and AI assets in Azure Databricks with users outside your organization, regardless of whether they use Azure Databricks.",GA,-,-,Docs,2026-02-08
Data sharing,Delta Sharing with deletion vectors/column mapping,https://learn.microsoft.com/en-gb/azure/databricks/delta-sharing/,"Share tables that use deletion vectors, column mapping, or UniForm via Delta Sharing. Sub-feature of Delta Sharing.",PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Data sharing,Delta Sharing for foreign tables,https://learn.microsoft.com/en-gb/azure/databricks/delta-sharing/,Share foreign Iceberg tables via Delta Sharing. Sub-feature of Delta Sharing.,BETA,-,-,Docs,2026-02-09
Data sharing,Open sharing,https://learn.microsoft.com/en-gb/azure/databricks/delta-sharing/read-data-open,This page describes how to read data shared with you using the Delta Sharing open sharing protocol with bearer tokens. It includes instructions for reading shared data using the following tools:,GA,-,-,Docs,2026-02-08
Data sharing,Databricks Marketplace,https://learn.microsoft.com/en-gb/azure/databricks/marketplace/get-started-consumer,This article describes how to access data products in Databricks Marketplace if you have an Azure Databricks workspace that is enabled for Unity Catalog.,GA,-,-,Docs,2026-02-08
Data sharing,Databricks-to-Databricks sharing,https://learn.microsoft.com/en-gb/azure/databricks/delta-sharing/read-data-databricks,"This page describes how to read data shared with you using the Databricks-to-Databricks Delta Sharing protocol, where Databricks manages a secure connection for data sharing.",GA,-,-,Docs,2026-02-08
Data sharing,D2D sharing > Read shared managed Iceberg tables,https://learn.microsoft.com/en-gb/azure/databricks/delta-sharing/read-data-databricks,Read shared managed Iceberg tables via the Databricks-to-Databricks sharing protocol. Sub-feature of D2D sharing.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Data sharing,Sharing Materialization History System Table,https://docs.databricks.com/aws/en/admin/system-tables/materialization,"Enables the system.sharing schema, which contains one system table: materialization_history. The schema will become visible in your metastore within 24h. Note that you must grant SELECT rights to the users as described in the documentation.",PUBLIC_PREVIEW,-,Low,Account,2026-02-05
Data sharing,Sharing To Iceberg Clients,https://docs.databricks.com/aws/en/delta-sharing/create-share#iceberg-clients,"Enable customers to sharing Table/View/Materialized View/Streaming Table and Foreign Iceberg Table to Iceberg Clients, i.e., Spark Iceberg or Snowflake.",PUBLIC_PREVIEW,-,Medium — data shared to external Iceberg clients leaves platform,Account,2026-02-05
Data sharing,Delta Sharing for Default Storage – Expanded Access,https://docs.databricks.com/aws/en/delta-sharing/create-share,"This preview extends Delta Sharing of Default Storage assets to support cross-region, cross-cloud, and open recipients. It also adds the ability for recipients to access Default Storage assets from classic clusters, giving you more flexibility in how and where you share data.",BETA,-,"High — cross-region/cross-cloud sharing, open recipients",Account,2026-02-05
Data sharing,Lakehouse Federation Sharing,,"The Delta Sharing on Lakehouse Federation feature allows data providers to securely share data from its original location, bypassing the need to copy data into Databricks. By supporting provider-side materialization, the data is queried and materialized on the provider’s side before it is returned to the recipients, enabling seamless data sharing without complex network setup or credential transfers.",BETA,-,Medium — provider-side materialization runs on your infra,Account,2026-02-05
Data warehousing,Allow users to enable the new SQL editor for queries,https://docs.databricks.com/en/sql/user/sql-editor/new.html,"The new SQL editor offers improved performance and introduces features like multiple statement results, Git integration, and real-time collaboration with user presence and comments.",GA,-,Low,Workspace,2026-02-05
Data warehousing,Metric views,https://learn.microsoft.com/en-gb/azure/databricks/metric-views/data-modeling/,"This page describes how to model metric views and best practices for working with them. Metric views help to create a semantic layer for your data, transforming raw tables into standardized, business-friendly metrics.",GA,-,-,Docs,2026-02-08
Data warehousing,Metric view window measures,https://learn.microsoft.com/en-gb/azure/databricks/metric-views/data-modeling/,Window measures for metric views enabling time-based and partition-based aggregate calculations. Sub-feature of metric views.,EXPERIMENTAL,-,-,Docs,2026-02-09
Data warehousing,SQL Alerts V2,https://docs.databricks.com/aws/en/sql/user/alerts,"The next generation of Databricks SQL Alerts - with a revamped user interface, a simplified data model, evaluation history, and improved API support.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Data warehousing,SQL auto-formatting,https://learn.microsoft.com/en-gb/azure/databricks/sql/user/sql-editor/custom-format,This article explains how to customize SQL auto-formatting options in the Azure Databricks UI. Overview SQL formatting improves the readability and maintainability of your queries.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Data warehousing,Query performance insights,https://learn.microsoft.com/en-gb/azure/databricks/sql/user/queries/performance-insights,"This feature is in Private Preview. To try it, reach out to your Azure Databricks contact.",PRIVATE_PREVIEW,-,-,Docs,2026-02-08
Data warehousing,Warehouse Activity Details,https://learn.microsoft.com/azure/databricks/compute/sql-warehouse/monitor#metrics,"Provides deeper visibility into SQL Warehouse usage by showing why a warehouse is running even when no queries are visible. The SQL Warehouse monitoring UI includes an activity details view in the running clusters chart, showing query execution and client-driven activity, such as open sessions or query fetching.",BETA,-,Low,Workspace,2026-02-05
Developers,Databricks Connect (legacy),https://learn.microsoft.com/en-gb/azure/databricks/dev-tools/databricks-connect-legacy,Databricks Connect recommends that you use Databricks Connect for Databricks Runtime 13.0 and above instead. Databricks plans no new feature work for Databricks Connect for Databricks Runtime 12.2 LTS and below.,GA,-,-,Docs,2026-02-08
Developers,Databricks SQL Driver for Go,https://learn.microsoft.com/en-gb/azure/databricks/dev-tools/go-sql-driver,"The Databricks SQL Driver for Go is a Go library that allows you to use Go code to run SQL commands on Azure Databricks compute resources. This article supplements the Databricks SQL Driver for Go README, API reference, and examples. Requirements",GA,-,-,Docs,2026-02-08
Developers,Databricks CLI,https://learn.microsoft.com/en-gb/azure/databricks/dev-tools/cli/bundle-commands,"This information applies to Databricks CLI versions 0.205 and above. The Databricks CLI is in Public Preview. Databricks CLI use is subject to the Databricks License and Databricks Privacy Notice, including any Usage Data provisions.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Developers,Databricks Utilities,https://learn.microsoft.com/en-gb/azure/databricks/dev-tools/databricks-utils,"This article contains reference for Databricks Utilities (dbutils). The utilities provide commands that enable you to work with your Databricks environment from notebooks. For example, you can manage files and object storage, and work with secrets.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Developers,Enable networking for UDFs in Serverless SQL Warehouses,https://docs.databricks.com/aws/en/security/network/serverless-network-security/manage-network-policies#validate-with-databricks-sql,Enables internet access from User Defined Functions (UDFs) for Serverless SQL Warehouses. UDFs can now make network calls including downloading files and sending requests. Note that this opens up exfiltration of input data to the UDFs to the external network. Enabling this preview on Serverless Warehouses takes up to 15 minutes.,PUBLIC_PREVIEW,-,"High — opens internet egress from UDFs, data exfiltration risk",Workspace,2026-02-05
Developers,Enhanced Python UDFs in Unity Catalog,https://docs.databricks.com/en/udf,"Added support for custom dependencies from PyPI in UC Python UDFs (Databricks Runtime 16.2 and above), UC service credentials and batched execution (both Databricks Runtime 16.3 and above) to Python UDFs in Unity Catalog. Available on SQL warehouses (Pro and Serverless), Serverless Jobs and Notebooks and UC-enabled clusters. To leverage UC Python UDF environments on Serverless SQL, ""Enable networking for UDFs in Serverless SQL Warehouses"" must be enabled as well. Enabling this preview on Serverless Warehouses, jobs and notebooks takes up to 24 hours. This preview also enables Databricks Connect Python UDF dependencies (Databricks Runtime 16.4 and above), see the docs here: https://docs.databricks.com/aws/en/dev-tools/databricks-connect/python/udf",PUBLIC_PREVIEW,-,"Medium — custom PyPI deps in UDFs, supply chain risk",Workspace,2026-02-05
Developers,Focused notebook & file editor for Git folders,https://docs.databricks.com/aws/en/workspace/workspace-browser#authoring-contexts,"Similar to opening a folder in an IDE, you can now set the scope of the notebook and file editor to a specific Git folder. When the scope is set to a Git folder, the side panel displays that folder’s contents as an expandable tree, and the editor’s tab bar displays only the files, notebooks, and queries opened while the scope is set to that folder.",PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Developers,GitHub Actions,https://learn.microsoft.com/en-gb/azure/databricks/dev-tools/ci-cd/github,"GitHub Actions trigger runs of your CI/CD flows from your GitHub repositories and allow you to automate your build, test, and deployment CI/CD pipeline.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Developers,Serverless Private Git,https://learn.microsoft.com/en-us/azure/databricks/repos/serverless-private-git,Simplify the process of using Private Git Networking with the use of Serverless Private Link.  Avaialable on AWS and Azure.,PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Developers,Git CLI support for Git folders,https://learn.microsoft.com/en-us/azure/databricks/repos/git-operations-with-repos#use-git-cli-commands-beta,"You can now run Git CLI commands against Git folders in the Web Terminal and from notebooks. Previously, there was only support for Git operations via the UI.",BETA,-,Low,Workspace,2026-02-05
Developers,Databricks SDK for Go,https://learn.microsoft.com/en-gb/azure/databricks/dev-tools/sdk-go,"This feature is in Beta and is okay to use in production. During the Beta period, Databricks recommends that you pin a dependency on the specific minor version of the Databricks SDK for Go that your code depends on, for example, in a project's go.mod...",BETA,-,-,Docs,2026-02-08
Developers,Tree view of the side panel file browser,,"The file browser in the editor’s side panel now supports a tree view, allowing you to expand multiple folders at once and quickly navigate between files across directories without backtracking.",BETA,-,Low,Workspace,2026-02-05
Developers,Databricks Asset Bundles,https://learn.microsoft.com/en-gb/azure/databricks/dev-tools/bundles/direct,"Databricks Asset Bundles was originally built on top of the Databricks Terraform provider to manage deployments. However, in an effort to move away from this dependency, Databricks CLI version 0.279.0 and above supports two different deployment engin...",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Developers,DAB Direct Deployment Engine,https://learn.microsoft.com/en-gb/azure/databricks/dev-tools/bundles/direct,"The direct deployment engine for Databricks Asset Bundles, replacing the Terraform-based engine. Sub-feature of DABs.",EXPERIMENTAL,-,-,Docs,2026-02-09
Developers,dbutils.data utility,https://learn.microsoft.com/en-gb/azure/databricks/dev-tools/databricks-utils,The Databricks Utilities data module (dbutils.data) for data exploration and summarization.,EXPERIMENTAL,-,-,Docs,2026-02-09
Developers,dbutils.notebook utility,https://learn.microsoft.com/en-gb/azure/databricks/dev-tools/databricks-utils,The Databricks Utilities notebook module (dbutils.notebook) for chaining notebook executions.,EXPERIMENTAL,-,-,Docs,2026-02-09
Notebooks,Databricks Assistant Agent Mode,https://learn.microsoft.com/en-us/azure/databricks/notebooks/ds-agent,"Databricks Assistant Agent Mode can automate multiple steps. From a single prompt, it can retrieve relevant assets, generate and run code, fix errors automatically, and visualize results. It can sample data and cell outputs to provide better results.",GA_SOON,-,Medium — AI agent executes code autonomously,Workspace,2026-02-05
OLTP databases (Lakebase),Lakebase Postgres,https://learn.microsoft.com/en-us/azure/databricks/oltp,"A new Postgres compute type built for low-latency reads and writes. Autoscaling offers autoscaling compute, branching, instance restore, and more, while Provisioned provides high availability (HA) and integration with Databricks Apps.",PUBLIC_PREVIEW,-,"Medium — new compute type, operational maturity risk",Workspace,2026-02-05
OLTP databases (Lakebase),Lakebase Autoscaling,https://learn.microsoft.com/en-us/azure/databricks/oltp,"Autoscaling compute for Lakebase with scale-to-zero, branching, and instant restore. Available in eastus2, westeurope, westus.",BETA (3 regions),-,-,Docs,2026-02-08
OLTP databases (Lakebase),PostgREST API support,https://learn.microsoft.com/en-us/azure/databricks/oltp,PostgREST API interface for Lakebase Postgres databases.,PRIVATE_PREVIEW,-,-,Docs,2026-02-08
Reference,Error handling,https://learn.microsoft.com/en-gb/azure/databricks/error-messages/,When Azure Databricks raises an error it includes the following components:,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Reference,PySpark geospatial functions (st_addpoint),https://learn.microsoft.com/en-gb/azure/databricks/pyspark/reference/functions/st_addpoint,"Adds a new point to the n-th position in the input linestring Geography or Geometry. For the corresponding Databricks SQL function, see st_addpoint function. Syntax",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Resources,Create cluster UI legacy (archive),https://learn.microsoft.com/en-gb/azure/databricks/archive/compute/configure,"These are instructions for the legacy create cluster UI, and are included only for historical accuracy. All customers should be using the updated create cluster UI.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Resources,Legacy UniForm IcebergCompatV1 (archive),https://learn.microsoft.com/en-gb/azure/databricks/archive/legacy/uniform,"This documentation has been retired and might not be updated. The products, services, or technologies mentioned in this content are no longer supported. See Read Delta tables with Iceberg clients.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Resources,Legacy MLflow Model Serving (archive),https://learn.microsoft.com/en-gb/azure/databricks/archive/legacy-model-serving/model-serving,"This documentation has been retired and might not be updated. The products, services, or technologies mentioned in this content are no longer supported. The guidance in this article is for Legacy MLflow Model Serving.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Resources,ABAC public preview transition (archive),https://learn.microsoft.com/en-gb/azure/databricks/archive/unity-catalog/abac-public-preview-transition,"This documentation has been retired and might not be updated. The products, services, or technologies mentioned in this content are no longer supported. See Unity Catalog attribute-based access control (ABAC).",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Security & compliance,Change default workspace access to Consumer,https://learn.microsoft.com/en-gb/azure/databricks/security/auth/change-default-workspace-access,This page explains how workspace admins can change the default workspace access for new users to consumer access by using group cloning.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Security & compliance,Compliance security profile,https://learn.microsoft.com/en-gb/azure/databricks/security/privacy/security-profile,"This page describes the compliance security profile, its compliance controls, and supported features. To enable the compliance security profile, see Configure enhanced security and compliance settings.",GA,-,-,Docs,2026-02-08
Security & compliance,Update workspace VNet configuration,https://learn.microsoft.com/en-gb/azure/databricks/security/network/classic/update-workspaces,This page provides step-by-step instructions for updating the virtual network (VNet) configuration of an existing an Azure Databricks workspace.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Security & compliance,Context-based Ingress Control,https://learn.microsoft.com/en-us/azure/databricks/security/network/front-end/context-based-ingress,"Context-based ingress control enables access decisions based on identity, source network and destination API scopes. Warning: disabling this preview will not disable enforcement. Update your ingress policies to allow access from all sources, or delete your ingress policies, before turning off Context-based Ingress Control.",PUBLIC_PREVIEW,-,High — ingress policy changes affect all workspace access,Account,2026-02-05
Security & compliance,Secrets in Spark configuration and environment variables,https://learn.microsoft.com/en-gb/azure/databricks/security/secrets/secrets-spark-conf-env-var,This article provides details about how to reference a secret in a Spark configuration property or environment variable. Retrieved secrets are redacted from notebook output and Spark driver and executor logs.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Security & compliance,CMK-encrypted Managed Catalogs,https://docs.databricks.com/gcp/en/security/keys/customer-managed-keys,"When enabled, this flag allows you to create Catalogs encrypted with your Customer Managed Keys (CMK). Data stored at rest is encrypted. If the specified CMK is disabled or deleted from your cloud account, we will no longer be able to access your data. Only Databricks-managed data is encrypted. Any data hosted on your personal cloud is not encrypted.",BETA,-,High — key deletion causes permanent irrecoverable data loss,Account,2026-02-05
Security & compliance,Enforce IP access list on Compute Plane Requests,https://community.databricks.com/t5/product-platform-updates/action-required-azure-update-outbound-connectivity-for-classic/ba-p/70060,"Enable the enforcement of IP access list on certified requests from compute plane to access your workspaces. When this preview is off, Databricks allows certified requests from the compute plane to access your workspace regardless of the workspace IP access list.",-,-,High — may break compute plane connectivity if IP lists are misconfigured,Workspace,2026-02-05
Sign up for Databricks,Community Edition migration to Free Edition,https://learn.microsoft.com/en-gb/azure/databricks/getting-started/ce-migration,"With the release of Databricks Free Edition, Community Edition (CE) will soon be retired. Community Edition workspace owners should use the workspace migration tool to migrate to Free Edition as soon as possible.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Tables,Liquid clustering,https://learn.microsoft.com/en-gb/azure/databricks/delta/clustering,Liquid clustering is a data layout optimization technique that replaces table partitioning and ZORDER. It simplifies table management and optimizes query performance by automatically organizing data based on clustering keys.,GA,-,-,Docs,2026-02-08
Tables,Liquid clustering for Iceberg tables,https://learn.microsoft.com/en-gb/azure/databricks/delta/clustering,Liquid clustering support for managed Apache Iceberg tables. Sub-feature of Liquid clustering.,PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Tables,Isolation levels and write conflicts,https://learn.microsoft.com/en-gb/azure/databricks/optimizations/isolation-level,The isolation level of a table defines the degree to which a transaction must be isolated from modifications made by concurrent operations. Write conflicts on Azure Databricks depend on the isolation level.,GA,-,-,Docs,2026-02-08
Tables,VACUUM with predictive optimization,https://learn.microsoft.com/en-gb/azure/databricks/delta/vacuum,Predictive optimization automatically runs VACUUM on Unity Catalog managed tables. Databricks recommends enabling predictive optimizations for all Unity Catalog managed tables to simplify data maintenance and reduce storage costs.,PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Tables,Row and column filters,https://learn.microsoft.com/en-gb/azure/databricks/data-governance/unity-catalog/filters-and-masks/,This page provides guidance for using row filters and column masks to filter sensitive data in your tables. What are row filters? Row filters let you control which rows a user can access in a table based on custom logic.,GA,-,-,Docs,2026-02-08
Tables,Convert foreign tables to external,https://learn.microsoft.com/en-gb/azure/databricks/tables/convert-foreign-external,"This feature is in Public Preview and is only available to participating customers at this time. To participate in the preview, apply by filling out this form.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Tables,Iceberg V3,https://docs.databricks.com/aws/en/iceberg/iceberg-v3,"Iceberg V3 adds performance and feature capabilities to Delta UniForm and Managed Iceberg tables. These features include deletion vectors for efficient row-level deletes, row lineage for incremental processing, and the Variant data type for semi-structured data.",BETA,-,Low,Workspace,2026-02-05
Tables,Variant Shredding for Optimized Read Performance on Semi-Structured Data,https://learn.microsoft.com/en-us/azure/databricks/delta/variant-shredding,"Variant shredding extracts commonly occurring fields in semi-structured data into separate columns during writes. This significantly improves read performance, but incurs some overhead on writes. Variant shredding is supported in DBR 17.2 and above.",BETA,-,Low,Workspace,2026-02-05
Technology partners,Google Sheets connector,https://learn.microsoft.com/en-gb/azure/databricks/integrations/google-sheets,"This page describes how to use the Databricks Connector for Google Sheets to connect to Azure Databricks from Google Sheets. The Databricks Connector queries Azure Databricks data from within Google Sheets, enabling further analysis. Before you begin",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Technology partners,Databricks sign-on from dbt Core with Entra ID,https://learn.microsoft.com/en-gb/azure/databricks/integrations/configure-oauth-dbt,"This page describes how to configure Azure Databricks sign-on from dbt Core with Microsoft Entra ID. After you complete this one-time configuration as an Azure Databricks account admin, users can connect Azure Databricks to dbt Core using single sign...",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Technology partners,Qlik Replicate,https://learn.microsoft.com/en-gb/azure/databricks/partners/ingestion/qlik,"Qlik Replicate helps you pull data from multiple data sources (Oracle, Microsoft SQL Server, SAP, mainframe and more) into Delta Lake.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Technology partners,Microsoft Foundry integration,https://learn.microsoft.com/en-gb/azure/databricks/integrations/microsoft-foundry,"This page explains how to add an Azure Databricks Genie Model Context Protocol (MCP) server as a tool in Microsoft Foundry, allowing your AI agents to connect and use the insights of Genie spaces.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Workspace UI,Partner-powered AI features,https://learn.microsoft.com/en-gb/azure/databricks/databricks-ai/partner-powered,"The partner-powered AI features setting controls whether some features are powered by models hosted by a partner provider. By default, this setting is enabled for all workspaces that do not have a compliance security profile (CSP) enabled.",GA,-,-,Docs,2026-02-08
Workspace UI,Databricks One,https://docs.databricks.com/aws/en/workspace/databricks-one,Enables the Databricks One business user experience for Consumer entitled users in the Workspace.,GA,-,Low,Workspace,2026-02-05
Workspace UI,Introduction to workspace objects,https://learn.microsoft.com/en-gb/azure/databricks/workspace/workspace-assets,"This article provides a high-level introduction to Azure Databricks workspace objects. You can create, view, and organize workspace objects in the workspace browser across personas.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Workspace UI,Navigate the workspace,https://learn.microsoft.com/en-gb/azure/databricks/workspace/navigate-workspace,"Learn how to navigate the Lakehouse workspace UI and find the features you need. This article explains the core concepts of the Azure Databricks workspace UI, an environment for authoring and accessing all of your Azure Databricks objects.",GA,-,-,Docs,2026-02-08
Workspace UI,Navigate the workspace > In-product help experience,https://learn.microsoft.com/en-gb/azure/databricks/workspace/navigate-workspace,"In-product help panel with Send Feedback, Help Center, and AI chatbot. Sub-feature of Navigate the workspace.",PUBLIC_PREVIEW,-,-,Docs,2026-02-09
Workspace UI,Search for workspace objects,https://learn.microsoft.com/en-gb/azure/databricks/search/,"This article describes how to search for tables, volumes, notebooks, queries, dashboards, alerts, files, folders, libraries, jobs, repos, partners, and Marketplace listings in your Azure Databricks workspace.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Workspace UI,Tagging support for workspace scoped assets,,Enable tags for new workspace scoped assets including lakeview dashboards and genie spaces. Users with edit level or above permissions can add and modify tags on the asset,PUBLIC_PREVIEW,-,Low,Workspace,2026-02-05
Apache Spark,Structured Streaming real-time mode,https://learn.microsoft.com/en-gb/azure/databricks/structured-streaming/real-time,"This page describes real-time mode, a trigger type for Structured Streaming that enables ultra-low latency data processing with end-to-end latency as low as 5 ms.",PUBLIC_PREVIEW,-,-,Docs,2026-02-08
Architecture,Performance efficiency best practices,https://learn.microsoft.com/en-gb/azure/databricks/lakehouse-architecture/performance-efficiency/best-practices,"This article covers best practices for performance efficiency, organized by architectural principles listed in the following sections. 1.",GA,-,-,Docs,2026-02-08
